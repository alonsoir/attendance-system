services:
  consul:
    image: hashicorp/consul:1.20
    env_file:
      - .env
    environment:
      - CONSUL_LOCAL_CONFIG={"verify_incoming":false}
    ports:
      - "8500:8500"
    networks:
      - default
    volumes:
      - consul-data:/consul/data
    command: agent -server -bootstrap-expect=1 -ui -bind=0.0.0.0 -client=0.0.0.0 -advertise=10.0.0.2
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8500/v1/status/leader || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5

  vault:
      image: hashicorp/vault:1.18
      container_name: vault
      restart: always
      env_file:
        - .env
      ports:
        - "8200:8200"
      environment:
        VAULT_API_ADDR: http://vault:8200
        VAULT_CLUSTER_ADDR: https://vault:8201
        VAULT_STORAGE: consul
        VAULT_BACKEND: consul
        VAULT_STORAGE_CONSUL_ADDRESS: http://consul:8500
      volumes:
        - ${PROJECT_ROOT}/backend/scripts:/scripts:ro
        - vault-data:/vault/data
      command: sh -c "sleep 10 && vault server -config=/scripts/vault.hcl"
      depends_on:
        - consul
      healthcheck:
        test: [ "CMD", "vault", "status" ]
        interval: 10s
        timeout: 5s
        retries: 3
      cap_add:
        - IPC_LOCK
      networks:
        - default

  vault-init:
      image: alpine:latest
      env_file:
        - .env
      depends_on:
        - vault
      environment:
        - VAULT_ADDR=http://vault:8200
        - CONSUL_ADDR=http://consul:8500
      networks:
        - default
      volumes:
        - .env:/app/.env:ro
        - /Users/aironman/git/attendance_system/backend/scripts:/scripts
        - vault-data:/vault/file
        - /Users/aironman/git/attendance_system/vault-init:/vault-init
      command: sh -c "chmod +x /scripts/simple-init-vault.sh && /scripts/simple-init-vault.sh"
  front:
    build:
      context: .
      dockerfile: attendance_system/frontend/Dockerfile
    image: frontend-attendance
    env_file:
      - .env
    environment:
      - VAULT_ADDR=http://vault:8200
      - VAULT_TOKEN=attendance_root_token
      - VITE_API_URL=http://back:8000
    networks:
      - default
    depends_on:
      - back
      - consul
      - vault
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health", "||", "exit", "1"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      replicas: 1
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs:/app/logs:rw

  back:
    build:
      context: .
      dockerfile: attendance_system/backend/Dockerfile
    image: backend-attendance
    env_file:
      - .env
    environment:
      - POSTGRES_SERVER=db
      - POSTGRES_PORT=5432
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - VAULT_ADDR=http://vault:8200
      - VAULT_TOKEN=attendance_root_token
      - PROJECT_NAME=${PROJECT_NAME}
      - PROJECT_DESCRIPTION=${PROJECT_DESCRIPTION}
      - VERSION=${VERSION}
      - API_V1_STR=${API_V1_STR}
      - BACKEND_CORS_ORIGINS=${BACKEND_CORS_ORIGINS}
      - ENABLE_METRICS=${ENABLE_METRICS}
      - SECRET_KEY=${SECRET_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    networks:
      - default
    depends_on:
      - vault
      - consul
      - db
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health", "||", "exit", "1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: 1
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./logs:/app/logs:rw

  db:
    image: test-postgres-encrypted:latest
    env_file:
      - .env
    environment:
      POSTGRES_USER: test_user
      POSTGRES_PASSWORD: test_password
      POSTGRES_DB: test_db
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 768MB
      POSTGRES_WORK_MEM: 16MB
    command: postgres -c "huge_pages=off"
    networks:
      - default
    ports:
      - "5432:5432"
    volumes:
      - db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U test_user -d test_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      replicas: 1
      resources:
        limits:
          memory: '1G'
        reservations:
          memory: '512M'
    depends_on:
      - consul
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    image: nginx:latest
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/html:/usr/share/nginx/html:ro
      - ./nginx/static:/usr/share/nginx/static:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    networks:
      - default
    environment:
      - NGINX_ENTRYPOINT_QUIET_LOGS=1
    depends_on:
      - front
      - back
      - consul
    healthcheck:
      test: [ "CMD", "nginx", "-t" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      replicas: 1
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
      image: redis:latest
      healthcheck:
        test: [ "CMD", "redis-cli", "ping" ]
        interval: 10s
        timeout: 5s
        retries: 5
      networks:
        - default
      deploy:
        replicas: 1
      depends_on:
        - consul
      logging:
        driver: "json-file"
        options:
          max-size: "10m"
          max-file: "3"

  prometheus:
      image: prom/prometheus:latest
      env_file:
        - .env
      ports:
        - "9090:9090"
      volumes:
        - ./prometheus:/etc/prometheus:ro
        - prometheus-data:/prometheus
      networks:
        - default
      depends_on:
        - back
        - consul
      deploy:
        replicas: 1
      logging:
        driver: "json-file"
        options:
          max-size: "10m"
          max-file: "3"

  grafana:
      image: grafana/grafana:latest
      env_file:
        - .env
      ports:
        - "3000:3000"
      environment:
        - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      networks:
        - default
      volumes:
        - grafana-data:/var/lib/grafana
      depends_on:
        - prometheus
        - consul
      deploy:
        replicas: 1
      logging:
        driver: "json-file"
        options:
          max-size: "10m"
          max-file: "3"

  falco:
      image: falcosecurity/falco:latest
      privileged: true
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock:ro
        - /proc:/host/proc:ro
        - /sys/kernel/debug:/sys/kernel/debug
        - /dev:/host/dev:ro
        - /etc:/host/etc:ro
        - /var/lib/docker:/var/lib/docker:ro
        - /run/containerd:/run/containerd:ro
      security_opt:
        - no-new-privileges:false
      environment:
        - FALCO_BPF_PROBE=""  # Forzar uso de eBPF
      command: >
        falco
        --cri /run/containerd/containerd.sock
        --driver bpf
        --modern-bpf
        -o json_output=true
        --stdout
        --severity=info
      depends_on:
        - consul
      networks:
        - default
      logging:
        driver: "json-file"
        options:
          max-size: "10m"
          max-file: "3"

volumes:
  vault-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  db-data:
    driver: local
  consul-data:
    driver: local

networks:
  default:
    driver: overlay
    ipam:
      config:
        - subnet: 10.0.0.0/24
          gateway: 10.0.0.1
    attachable: true